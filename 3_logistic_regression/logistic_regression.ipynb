{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hi!\n",
    "In today's workshop we are going to learn about most known concept of supervised learning which is **classification**.\n",
    "\n",
    "### What is classification?\n",
    "Classification is a problem of predicting discrete value (classes) for given features. It is mainly viewed as a supervised learning problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import solutions\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like last time, we'll work with a very real-world dataset describing a couple hundred cases of breast cancer, which presents an example of a case for **binary classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_breast_cancer().DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll split our data int train, test, and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, train_size=0.7)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, train_size=0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about applying linear regression for classification?\n",
    "\n",
    "Let's take a look at the target data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a bunch of ones and zeros! Wouldn't it make sense to just train a linear regressor on the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to interpret these predictions? Maybe we need something different?\n",
    "\n",
    "![classification_regression](img/clas_reg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is about applying a \"squashing\" function to the hypotheses when calculating loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$h_w(x) = \\sum_{j=0}^k w_j x_j = wx$$\n",
    "\n",
    "### $$\\hat{y} = \\sigma(h_w(x))$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need squashing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One of such squashing functions is sigmoid function:\n",
    "### $$\\sigma(x) = \\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, sigmoid(x))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid(np.inf), sigmoid(-np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because of non-linearities in our hypotheses, we also need to update our loss function.\n",
    "\n",
    "We'll use a logarythmic loss function which quite nicely captures an intuition, that we want the predictions datapoins which should be predicted as $0$ as close to $0$ as possible, and, analogically, predictions which should be $1$, as close to $1$ as possible:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$ L(w) = \\frac{-1}{n}(\\sum_{i=0}^n y^{(i)}\\log{h_w(x^{(i)})} + (1-y^{(i)})\\log{(1-h_w(x^{(i)}))} )$$\n",
    "\n",
    "### $$ y^{(i)} \\in \\{0, 1\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = 0\n",
    "x = np.linspace(0, 0.9999, 1000)\n",
    "plt.plot(x, -np.log(1 - x))\n",
    "plt.ylim(-1, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = 1\n",
    "x = np.linspace(0.0001, 1, 1000)\n",
    "plt.plot(x, -np.log(x))\n",
    "plt.ylim(-1, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and implement this new loss function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(\n",
    "    W: np.ndarray, \n",
    "    X: np.ndarray, \n",
    "    Y: np.ndarray, \n",
    "    eps: float = 0.01 # the epsilon parameter is for numeric stability of logarithm\n",
    ") -> float:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = solutions.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(X.shape[1])\n",
    "print(loss(W, X, y, eps=0.1))\n",
    "print(solutions.loss(W, X, y, eps=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about gradient descent procedure? How does it change? Let's derive the gradient!\n",
    "\n",
    "[we'll do that on the board] \n",
    "It turns out, it's very simple!\n",
    "\n",
    "### $$\n",
    "\\frac{\\partial L(W)}{\\partial W} =\\frac{1}{n}(\\sum_{i=0}^n x^{(i)} \\cdot (h_w(x^{(i)}) - y^{(i)}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_step(\n",
    "    W, \n",
    "    X, \n",
    "    Y,\n",
    "    learning_rate=0.01\n",
    ") -> np.ndarray:\n",
    "    return np.zeros_like(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_step = solutions.gradient_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(X.shape[1])\n",
    "\n",
    "yours = gradient_step(W, X, y, learning_rate=0.1)\n",
    "provided = solutions.gradient_step(W, X, y, learning_rate=0.1)\n",
    "print(yours - provided)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not forget about adding the bias feature and normalizing the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_feature(X):\n",
    "       return np.c_[np.ones(len(X)), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = add_bias_feature(X_train)\n",
    "X_val = add_bias_feature(X_val)\n",
    "X_test = add_bias_feature(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, *norm_parameters = solutions.std_normalization(X_train)\n",
    "X_val, *_ = solutions.std_normalization(X_val, *norm_parameters)\n",
    "X_test, *_ = solutions.std_normalization(X_test, *norm_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "W = np.random.randn(X_train.shape[1])\n",
    "train_costs = []\n",
    "val_costs = []\n",
    "train_steps = 100\n",
    "for _ in range(train_steps):\n",
    "    train_costs.append(loss(W, X_train, y_train, eps=0.001))\n",
    "    val_costs.append(loss(W, X_val, y_val, eps=0.001))\n",
    "    W = gradient_step(W, X_train, y_train, learning_rate=0.1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(train_steps), train_costs)\n",
    "plt.plot(np.arange(train_steps), val_costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, solutions._hypotheses(W, X_train) >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_val, solutions._hypotheses(W, X_val) >= 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does our model compare to the one provided by Scikit-Learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(C=10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A great score! Or is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_ind = np.argwhere(y_val == 1).reshape(-1)\n",
    "negative_ind = np.argwhere(y_val == 0).reshape(-1)\n",
    "X_val_pos = X_val[positive_ind]\n",
    "y_val_pos = y_val[positive_ind]\n",
    "X_val_neg = X_val[negative_ind]\n",
    "y_val_neg = y_val[negative_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_val_pos, solutions._hypotheses(W, X_val_pos) >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_val_neg, solutions._hypotheses(W, X_val_neg) >= 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve higher accuracies on positive examples, than on negative ones. In practice, this means we're likelier to classify tumors as malignant than not. \n",
    "\n",
    "Better safe than sorry? Turns out, not always. Can we dig deeper into the performance of our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and recall\n",
    "We can divide classifications of our model into four classes:\n",
    "\n",
    "| Predicted/Actual | 0   | 1   |\n",
    "|------------------|-----|-----|\n",
    "| 0                | True negative | False negative|\n",
    "| 1                | False positive | True positive | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy - a first intuition**\n",
    "\n",
    "$$\n",
    "Accuracy = \\frac{T_p + T_n}{T_n + T_p + F_n + F_p}\n",
    "$$\n",
    "\n",
    "However, as we've just seen, this metric may be deceiving (consider class imbalance!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out there is a more reliable way to measure the performance of our model:\n",
    "\n",
    "- **Precision** - *what fraction of our positive classifications is correct?*\n",
    "$$\n",
    "Precision = \\frac{T_p}{T_p + F_p}\n",
    "$$\n",
    "\n",
    "- **Recall** - *what fraction of actual positive examples has been classified correctly?*\n",
    "$$\n",
    "Recall = \\frac{T_p}{T_p + F_n}\n",
    "$$\n",
    "\n",
    "We want both of those values to be as high as possible (duh).\n",
    "\n",
    "However, sometimes we have to make a trade off between them and decide with our classification method that one will be higher and the other lower.\n",
    "\n",
    "A metric which nicely mixes the two above is called the **F1 score** - it's high when both precision and recall are high enough, but low when one of them is sacrificed for the sake of another.\n",
    "\n",
    "$$\n",
    "F1 = \\frac{2PR}{P +R}\n",
    "$$\n",
    "\n",
    "#### Can precision and recall be manipulated without tinkering with the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision_recall(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    W: np.ndarray,\n",
    "    threshold: float\n",
    "):\n",
    "    print(\"threshold\", threshold)\n",
    "    y_pred = solutions._hypotheses(W, X)\n",
    "    y_pred_bin = y_pred >= threshold\n",
    "    print('precision', precision_score(y, y_pred_bin))\n",
    "    print('recall', recall_score(y, y_pred_bin))\n",
    "    print('F1 score', f1_score(y, y_pred_bin))\n",
    "    positive_ind = np.argwhere(y == 1).reshape(-1)\n",
    "    negative_ind = np.argwhere(y == 0).reshape(-1)\n",
    "    y_pos = y[positive_ind]\n",
    "    y_neg = y[negative_ind]\n",
    "    y_pos_pred = y_pred_bin[positive_ind]\n",
    "    y_neg_pred = y_pred_bin[negative_ind]\n",
    "    print('total accuracy', accuracy_score(y, y_pred_bin))\n",
    "    print('positive accuracy', accuracy_score(y_pos, y_pos_pred))\n",
    "    print('negative accuracy', accuracy_score(y_neg, y_neg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(\n",
    "    calc_precision_recall,\n",
    "    X=fixed(X_val),\n",
    "    y=fixed(y_val),\n",
    "    W=fixed(W),\n",
    "    threshold=widgets.FloatSlider(\n",
    "        value=0.5,\n",
    "        min=0,\n",
    "        max=1,\n",
    "        step=0.01\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does F1 score depend on the threshhold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(.01, .99, 100)\n",
    "scores = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = solutions._hypotheses(W, X_val)\n",
    "    y_pred_bin = y_pred >= t\n",
    "    scores.append(f1_score(y_val, y_pred_bin))\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.plot(thresholds, scores)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To better visualize how precision and recall depend on each other, we can also plot an AUROC curve\n",
    "\n",
    "**A**rea\n",
    "\n",
    "**U**nder\n",
    "\n",
    "**R**eceiver\n",
    "\n",
    "**O**perating\n",
    "\n",
    "**C**haracteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(.01, .99, 100)\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = solutions._hypotheses(W, X_val)\n",
    "    y_pred_bin = y_pred >= t\n",
    "    precisions.append(precision_score(y_val, y_pred_bin))\n",
    "    recalls.append(recall_score(y_val, y_pred_bin))\n",
    "plt.xlim(0, 1.2)\n",
    "plt.ylim(0, 1.2)\n",
    "plt.grid(True)\n",
    "plt.plot(precisions, recalls)\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sometimes, binary classification is not enough!\n",
    "\n",
    "https://www.youtube.com/watch?v=pqTntG1RXSY\n",
    "\n",
    "### Multiclass classification\n",
    "\n",
    "To solve the problem of classifying an object as one of multiple classes, we do a one-vs-all prediction. \n",
    "Previously we calculated $h_w(x)$ and applied $sigmoid$ function to it, to calculate the 'probablility' of our example being positive or not. Since $\\hat{y} \\in [0,1]$, we chose a 'threshold' in that range below which we can treat our example as negative and above which - as positive.\n",
    "\n",
    "For multiple classes, we must essentially calculate a hypothesis for **every single one** of possible categories. If hypothesis for a given category is high enough, there is a high probability that our object is of that category. In the other case, it means that it belongs to some other category (but we don't know which one - we need other hypotheses for that). \n",
    "\n",
    "![alt text](img/multiclass.PNG)\n",
    "This is called one-versus-all classification. Ultimately we choose the category whose hypothesis has the highest probability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before\n",
    "\n",
    "Until now, a hypothesis $h_w(x^{(i)})$ for a given object $x^{(i)}$ represented as a vector of features $[x_0^{(i)}, x_1^{(i)}, ... x_k^{(i)}]$ was represented by a scalar:\n",
    "\n",
    "$$h_w(x) = \\sigma(\\sum_{j=0}^k w_j x_j) = \\sigma(wx)$$\n",
    "\n",
    "Where w was a vector a weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now\n",
    "\n",
    "If $m$ is the number of possible categories, then for every vector of features we want to perform multiple logistic regressions (for every possible category we might classify it as). \n",
    "Essentially, for every vector of $k$ features we now want to obtain a vector of $m$ hypothesis scalars:\n",
    "\n",
    "$$[x_0^{(i)}, x_1^{(i)}, ... x_k^{(i)}] \\xrightarrow{\\text{classification}} [h_0^{(i)}, h_1^{(i)}, ... h_m^{(i)}]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every logistic regression we need a separate $k$-dimensional vector (or a $k \\times 1$ matrix) of weights. \n",
    "If we want to vectorize our computations, we can merge all of the weights vectors into a single, $k \\times m$ matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X$ - an $n \\times k$ matrix representing the examples\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "x_0^{(1)} & x_1^{(1)}  &  & ...  &x_k^{(1)}\\\\ \n",
    "x_0^{(2)} &...  &  &...  & \\\\ \n",
    "... &  &  &...  & \\\\ \n",
    "x_0^{(n)} &  & ... &  & x_k^{(n)}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$W$ - an $k \\times m$ matrix representing weights in logistic regression for every feature in every category\n",
    "\n",
    "\\begin{bmatrix}\n",
    "w_0^{(1)} & w_0^{(2)}  &  & ...  &w_0^{(m)}\\\\ \n",
    "w_1^{(1)} &...  &  &...  & \\\\ \n",
    "... &  &  &...  & \\\\ \n",
    "w_k^{(1)} &  & ... &  & w_k^{(m)}\n",
    "\\end{bmatrix}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_W(X)$ - an $n \\times m$ matrix representing hypothesis vectors for every example and category \n",
    "\n",
    "$$\n",
    "h_W(X) = \\sigma(XW)\n",
    "$$\n",
    "\n",
    "We'll denote j-th hypothesis of i-th example as $$h_w^{(j)}(x^{(i)})$$\n",
    "Computationally-wise, the only thing that changes is the $m$ dimension of W.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As for cost function...\n",
    "\n",
    "$$ L^{(j)}(w) = -\\sum_{i=0}^n y^{(i,j)}\\log{h_w^{(j)}(x^{(i)})} + (1-y^{(i,j)})\\log{(1-h_w(x^{(i)}))}$$\n",
    "\n",
    "We have a vector of cost values for every category $j$, which is useful in updating weights in gradient descent. If we want to plot the cost function, we can sum or count the mean of all those values.\n",
    "\n",
    "Gradient descent also works the same way as before.\n",
    "\n",
    "#### WTF is $y^{(i,j)}$?\n",
    "\n",
    "We can now look at y as a matrix of one-hot values. If $y^{(i,j)} = 1 $, then example $i$ is of class $j$. \n",
    "\n",
    "This also means the rest of values in $y^{(i)}$ are, of course, zeros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = solutions._hypotheses\n",
    "loss = solutions.loss\n",
    "gradient_step = solutions.gradient_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST - something more ambitious\n",
    "\n",
    "MNIST is one of the most famous datasets for beginers in Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"train-images-idx3-ubyte\"):\n",
    "    !curl -O http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "    !curl -O http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "    !curl -O http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "    !curl -O http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "    !gunzip t*-ubyte.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = loadlocal_mnist(\n",
    "        images_path=\"train-images-idx3-ubyte\", \n",
    "        labels_path=\"train-labels-idx1-ubyte\")\n",
    "\n",
    "X2, y2 = loadlocal_mnist(\n",
    "        images_path=\"t10k-images-idx3-ubyte\", \n",
    "        labels_path=\"t10k-labels-idx1-ubyte\")\n",
    "\n",
    "X = np.concatenate([X1, X2])\n",
    "y = np.concatenate([y1, y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image of a digit can be visualized as array of $784 (= 28*28)$ numbers, or just a picture. \n",
    "For convenience values of pixels are stored not as a 2D array, but as a vector, so in order to be displayed, the vector must be reshaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = img.reshape(28,28) / 255\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to treat every single pixel as a separate feature. In order to do so, let's normalize them. We'll also create one-hot vectors of labels we can fit our model to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_count = X.shape[0]\n",
    "labels = y\n",
    "normalized_pixels_nobias = X / 255\n",
    "one_hot_labels = np.zeros((examples_count, 10))\n",
    "one_hot_labels[np.arange(examples_count), labels] = 1\n",
    "one_hot_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_mnist_elem(index):\n",
    "    img = X[rand_no]\n",
    "    pixels = img.reshape(28,28) / 255\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "    print('label:', labels[rand_no])\n",
    "    print('label as a one-hot vector:', one_hot_labels[rand_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_count = normalized_pixels_nobias.shape[0]\n",
    "rand_no = np.random.randint(0, examples_count)\n",
    "display_mnist_elem(rand_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_pixels = add_bias_feature(normalized_pixels_nobias) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(normalized_pixels, one_hot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the classifier will work the same as in binary classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.random((785,10)) # 784 + bias feature\n",
    "losses = []\n",
    "steps = 100\n",
    "\n",
    "for i in range(steps):\n",
    "    W = gradient_step(W, X_train, Y_train, learning_rate=0.1)\n",
    "    losses.append(loss(W, X_train, Y_train))\n",
    "\n",
    "plt.plot(np.arange(steps), losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing loss decrease is one thing, but let's see our classifier in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_no = np.random.randint(examples_count) # we choose a random digit from dataset\n",
    "display_mnist_elem(rand_no)\n",
    "img_pixels = normalized_pixels[rand_no]\n",
    "predicted_H = hypotheses(W, img_pixels)\n",
    "predicted_class = np.argmax(predicted_H)\n",
    "\n",
    "print('predicted hypotheses:', predicted_H)\n",
    "print('predicted_class:', predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_test = hypotheses(W, X_test)\n",
    "predicted_test_labels = np.argmax(H_test, axis=1)\n",
    "accuracy_score(np.argmax(Y_test, axis=1), predicted_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MNIST it's actually embarassingly bad (best models achieve even 99.9% accuracy), but it's not so bad for one matrix!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next time, Neural Networks! :O\n",
    "\n",
    "Spoiler alert!\n",
    "\n",
    "![spoiler](img/lr_spoiler.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
